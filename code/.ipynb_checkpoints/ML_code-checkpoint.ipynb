{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "071c2e47-cdc9-4401-8f14-cc07f71b9429",
   "metadata": {},
   "source": [
    "\n",
    "# AWS Í∏∞Î∞ò Î®∏Ïã† Îü¨Îãù ETL ÌååÏù¥ÌîÑÎùºÏù∏ÏùÑ ÌÜµÌïú Îã§Ï§ë Î∂ÑÎ•ò ÏòàÏ∏° Î™®Îç∏ÎßÅ\n",
    "\n",
    "### ÌîÑÎ°úÏ†ùÌä∏ ÏÑ§Î™Ö:\n",
    "Ïù¥ ÌîÑÎ°úÏ†ùÌä∏Îäî AWS Ïò§ÌîàÏÜåÏä§Î•º ÌôúÏö©ÌïòÏó¨ [MIT Supercloud Dataset](https://registry.opendata.aws/dcc/)ÏùÑ Ïù¥Ïö©Ìïú Îã§Ï§ë Î∂ÑÎ•ò ÏòàÏ∏° Î™®Îç∏ÏùÑ Í∞úÎ∞úÌïòÎäî Í≤ÉÏûÖÎãàÎã§. Îç∞Ïù¥ÌÑ∞ ÏàòÏßë, Ï†ïÏ†ú Î∞è Î≥ÄÌôò(ETL) Í≥ºÏ†ïÏùÄ AWS ÏÑúÎπÑÏä§(AWS S3, AWS Glue)Î•º ÌÜµÌï¥ ÏûêÎèôÌôîÎêòÎ©∞, Î®∏Ïã† Îü¨Îãù Î™®Îç∏Ïùò ÌïôÏäµÍ≥º ÏòàÏ∏°ÏùÄ AWS SageMakerÏóêÏÑú ÏàòÌñâÎê©ÎãàÎã§.\n",
    "\n",
    "### Ï£ºÏöî Î™©Ìëú:\n",
    "1. **Îç∞Ïù¥ÌÑ∞ ÏàòÏßë**: MIT Supercloud ÏãúÏä§ÌÖúÏóêÏÑú ÏàòÏßëÎêú ÎåÄÍ∑úÎ™® Î™®ÎãàÌÑ∞ÎßÅ Îç∞Ïù¥ÌÑ∞Î•º AWS S3Ïóê Ï†ÄÏû•ÌïòÏó¨ Í¥ÄÎ¶¨Ìï©ÎãàÎã§.\n",
    "2. **Îç∞Ïù¥ÌÑ∞ Ï†ïÏ†ú Î∞è ETL**: ÏàòÏßëÎêú Îç∞Ïù¥ÌÑ∞Î•º ÌÅ¥Î†åÏßïÌïòÍ≥† Î≥ÄÌôòÌïòÏó¨ Î®∏Ïã† Îü¨Îãù Î™®Îç∏ ÌïôÏäµÏóê Ï†ÅÌï©Ìïú ÌòïÌÉúÎ°ú Ï§ÄÎπÑÌï©ÎãàÎã§. Ïù¥ Í≥ºÏ†ïÏóêÎäî Îç∞Ïù¥ÌÑ∞ Ï°∞Ïù∏ Î∞è aggregation ÌòïÌÉúÏùò ÌÖåÏù¥Î∏îÎ°ú Ï†ÄÏû•ÌïòÎäî Í≤ÉÏù¥ Ìè¨Ìï®Îê©ÎãàÎã§.\n",
    "3. **Î™®Îç∏ Íµ¨Ï∂ï Î∞è ÏòàÏ∏°**: SageMakerÏóêÏÑú ÌïôÏäµ Ïä§ÌÅ¨Î¶ΩÌä∏Î•º ÏûëÏÑ±ÌïòÍ≥†, Î®∏Ïã† Îü¨Îãù ÎùºÏù¥Î∏åÎü¨Î¶¨Î•º ÌôúÏö©ÌïòÏó¨ Î™®Îç∏ÏùÑ Íµ¨ÏÑ±Ìï©ÎãàÎã§. Ïù¥ÌõÑ Î™®Îç∏ ÏÑ±Îä•ÏùÑ ÌèâÍ∞ÄÌïòÏó¨ ÏµúÍ≥† ÏÑ±Îä•Ïùò Î™®Îç∏ÏùÑ ÏÑ†Ï†ïÌï©ÎãàÎã§.\n",
    "\n",
    "Ìï¥Îãπ ÌîÑÎ°úÏ†ùÌä∏Îäî AWS Ïù∏ÌîÑÎùºÎ•º ÌôúÏö©ÌïòÏó¨ Ìö®Ïú®Ï†ÅÏù∏ ÎπÖÎç∞Ïù¥ÌÑ∞ Ï≤òÎ¶¨ÏôÄ Ï†ÄÏû•, Î™®Îç∏ ÌïôÏäµÍπåÏßÄ AWS SageMakerÏôÄ ETL ÏõåÌÅ¨ÌîåÎ°úÏö∞Î•º ÏÇ¨Ïö©ÌïòÏó¨ ÏÑ§Í≥ÑÌïòÏòÄÏäµÎãàÎã§. üåü"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed021c96-7329-4e79-8c8b-9269436c457d",
   "metadata": {},
   "source": [
    "## 1. Install Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a291728-a581-4a82-9e64-547bf22f2f33",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting catboost\n",
      "  Downloading catboost-1.2.5-cp310-cp310-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
      "Collecting lightgbm\n",
      "  Downloading lightgbm-4.5.0.tar.gz (1.7 MB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting xgboost\n",
      "  Downloading xgboost-2.1.1-py3-none-manylinux2014_x86_64.whl.metadata (2.0 kB)\n",
      "Collecting graphviz (from catboost)\n",
      "  Downloading graphviz-0.20.3-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: matplotlib in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from catboost) (3.8.4)\n",
      "Requirement already satisfied: numpy>=1.16.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from catboost) (1.26.4)\n",
      "Requirement already satisfied: pandas>=0.24 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from catboost) (1.5.3)\n",
      "Requirement already satisfied: scipy in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from catboost) (1.13.1)\n",
      "Requirement already satisfied: plotly in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from catboost) (5.22.0)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pandas>=0.24->catboost) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pandas>=0.24->catboost) (2024.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from matplotlib->catboost) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from matplotlib->catboost) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from matplotlib->catboost) (4.53.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from matplotlib->catboost) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from matplotlib->catboost) (21.3)\n",
      "Requirement already satisfied: pillow>=8 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from matplotlib->catboost) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from matplotlib->catboost) (3.1.2)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from plotly->catboost) (8.3.0)\n",
      "Downloading catboost-1.2.5-cp310-cp310-manylinux2014_x86_64.whl (98.2 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m98.2/98.2 MB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0mm\n",
      "\u001b[?25hDownloading xgboost-2.1.1-py3-none-manylinux2014_x86_64.whl (4.5 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m46.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading graphviz-0.20.3-py3-none-any.whl (47 kB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m47.1/47.1 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: lightgbm\n",
      "  Building wheel for lightgbm (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for lightgbm: filename=lightgbm-4.5.0-py3-none-linux_x86_64.whl size=2740292 sha256=1b8b5e95d9b08769ccffb35f7f08dc76ee656c4c8de37199c26510ef1a0b46ed\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/7c/16/bf/61bc6295609c0752bc0f5b774a41f3413bca3afe3a73d2e47d\n",
      "Successfully built lightgbm\n",
      "Installing collected packages: graphviz, xgboost, lightgbm, catboost\n",
      "Successfully installed catboost-1.2.5 graphviz-0.20.3 lightgbm-4.5.0 xgboost-2.1.1\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (1.5.3)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (1.26.4)\n",
      "Requirement already satisfied: boto3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (1.34.142)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pandas) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: botocore<1.35.0,>=1.34.142 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from boto3) (1.34.142)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from boto3) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from boto3) (0.10.1)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from botocore<1.35.0,>=1.34.142->boto3) (2.2.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install catboost lightgbm xgboost\n",
    "!pip install pandas numpy boto3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de2febf-645d-4796-9d56-66e3d2ef9505",
   "metadata": {},
   "source": [
    "## 2. Data Loading\n",
    "AWS S3ÏúºÎ°ú Î∂ÄÌÑ∞ CSV ÌååÏùºÏùÑ Î°úÎìúÌï©ÎãàÎã§."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "201b0da4-ba9a-4013-a242-7d6519e9a756",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                id_job    id_array_job  id_array_task         id_user  \\\n",
      "0       65590191436871  14108987335445            114  87509498710061   \n",
      "1       64310074400647  61177129314629            600  42770088536256   \n",
      "2       34191949612627  14108987335445            115  87509498710061   \n",
      "3       21630303188597  61177129314629            601  42770088536256   \n",
      "4       10343100598054  61177129314629            602  42770088536256   \n",
      "...                ...             ...            ...             ...   \n",
      "395909  75124122894379  16618712154521     4294967294   1706828023724   \n",
      "395910  37802476679519  16618712154521     4294967294   1706828023724   \n",
      "395911   9807128696900  38040778438207            109  48065336140816   \n",
      "395912  42865228158509  38040778438207            110  48065336140816   \n",
      "395913  36690157579853  38040778438207            111  48065336140816   \n",
      "\n",
      "           kill_requid  nodes_alloc  cpus_req  derived_ec  exit_code  \\\n",
      "0       61026541062099            1        20           0          0   \n",
      "1       61026541062099            1        20           0          0   \n",
      "2       61026541062099            1        20           0          0   \n",
      "3       61026541062099            1        20           0          0   \n",
      "4       61026541062099            1        20           0          0   \n",
      "...                ...          ...       ...         ...        ...   \n",
      "395909  61026541062099            1        10           0          0   \n",
      "395910  61026541062099            1        10           0          0   \n",
      "395911  61026541062099            1        20           0          0   \n",
      "395912  61026541062099            1        20           0          0   \n",
      "395913  61026541062099            1        20           0          0   \n",
      "\n",
      "        gres_used  ...  tres_alloc_fs  tres_req_vmem tres_alloc_vmem  \\\n",
      "0             NaN  ...              0              0               0   \n",
      "1             NaN  ...              0              0               0   \n",
      "2             NaN  ...              0              0               0   \n",
      "3             NaN  ...              0              0               0   \n",
      "4             NaN  ...              0              0               0   \n",
      "...           ...  ...            ...            ...             ...   \n",
      "395909        NaN  ...              0              0               0   \n",
      "395910        NaN  ...              0              0               0   \n",
      "395911        NaN  ...              0              0               0   \n",
      "395912        NaN  ...              0              0               0   \n",
      "395913        NaN  ...              0              0               0   \n",
      "\n",
      "        tres_req_pages  tres_alloc_pages tres_req_gpu:tesla  \\\n",
      "0                    0                 0                  0   \n",
      "1                    0                 0                  0   \n",
      "2                    0                 0                  0   \n",
      "3                    0                 0                  0   \n",
      "4                    0                 0                  0   \n",
      "...                ...               ...                ...   \n",
      "395909               0                 0                  0   \n",
      "395910               0                 0                  0   \n",
      "395911               0                 0                  0   \n",
      "395912               0                 0                  0   \n",
      "395913               0                 0                  0   \n",
      "\n",
      "        tres_alloc_gpu:tesla  tres_req_gpu:volta  tres_alloc_gpu:volta  model  \n",
      "0                          0                   0                     0    NaN  \n",
      "1                          0                   0                     0    NaN  \n",
      "2                          0                   0                     0    NaN  \n",
      "3                          0                   0                     0    NaN  \n",
      "4                          0                   0                     0    NaN  \n",
      "...                      ...                 ...                   ...    ...  \n",
      "395909                     0                   1                     1    NaN  \n",
      "395910                     0                   1                     1    NaN  \n",
      "395911                     0                   1                     1    NaN  \n",
      "395912                     0                   1                     1    NaN  \n",
      "395913                     0                   1                     1    NaN  \n",
      "\n",
      "[395914 rows x 46 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import boto3\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "# s3ÏóêÏÑú Îç∞Ïù¥ÌÑ∞ Î°úÎìú\n",
    "df = pd.read_csv('s3a://testawsbucket-01/output/merged_df.csv/part-00000-bbb9f4ff-1108-4b02-96b3-7188aa8d7ccf-c000.csv', low_memory=False)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f82b2eb-acf6-426f-8999-8eaf5dea027f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3. Pre-processing\n",
    "Í≤∞Ï∏°Ïπò Î∞è Î≤îÏ£ºÌòï Î≥ÄÏàò Ïù∏ÏΩîÎî© ÏûëÏóÖÏùÑ ÏàòÌñâÌï©ÎãàÎã§.\n",
    "(ÏùºÎ∂Ä Ï†ÑÏ≤òÎ¶¨ÏôÄ ÌîºÏ≤ò ÏóîÏßÄÎãàÏñ¥ÎßÅ Í≥ºÏ†ïÏùÄ ETL Í≥ºÏ†ïÏóêÏÑú ÏàòÌñâ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d41cdb6d-de35-4c4d-b094-4937cbfa8bb0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 395914 entries, 0 to 395913\n",
      "Data columns (total 46 columns):\n",
      " #   Column                Non-Null Count   Dtype  \n",
      "---  ------                --------------   -----  \n",
      " 0   id_job                395914 non-null  int64  \n",
      " 1   id_array_job          395914 non-null  int64  \n",
      " 2   id_array_task         395914 non-null  int64  \n",
      " 3   id_user               395914 non-null  int64  \n",
      " 4   kill_requid           395914 non-null  int64  \n",
      " 5   nodes_alloc           395914 non-null  int64  \n",
      " 6   cpus_req              395914 non-null  int64  \n",
      " 7   derived_ec            395914 non-null  int64  \n",
      " 8   exit_code             395914 non-null  int64  \n",
      " 9   gres_used             0 non-null       float64\n",
      " 10  array_max_tasks       395914 non-null  int64  \n",
      " 11  array_task_pending    395914 non-null  int64  \n",
      " 12  constraints           395914 non-null  object \n",
      " 13  flags                 395914 non-null  int64  \n",
      " 14  mem_req               395914 non-null  uint64 \n",
      " 15  partition             395914 non-null  object \n",
      " 16  priority              395914 non-null  int64  \n",
      " 17  state                 395914 non-null  int64  \n",
      " 18  timelimit             395914 non-null  int64  \n",
      " 19  time_suspended        395914 non-null  int64  \n",
      " 20  track_steps           395914 non-null  int64  \n",
      " 21  job_type              395914 non-null  object \n",
      " 22  is_gpu                395914 non-null  int64  \n",
      " 23  time_duration         395914 non-null  int64  \n",
      " 24  submission_delay      395914 non-null  int64  \n",
      " 25  tres_req_cpu          395914 non-null  int64  \n",
      " 26  tres_alloc_cpu        395914 non-null  int64  \n",
      " 27  tres_req_mem          395914 non-null  int64  \n",
      " 28  tres_alloc_mem        395914 non-null  int64  \n",
      " 29  tres_req_energy       395914 non-null  int64  \n",
      " 30  tres_alloc_energy     395914 non-null  uint64 \n",
      " 31  tres_req_node         395914 non-null  int64  \n",
      " 32  tres_alloc_node       395914 non-null  int64  \n",
      " 33  tres_req_billing      395914 non-null  int64  \n",
      " 34  tres_alloc_billing    395914 non-null  int64  \n",
      " 35  tres_req_fs           395914 non-null  int64  \n",
      " 36  tres_alloc_fs         395914 non-null  int64  \n",
      " 37  tres_req_vmem         395914 non-null  int64  \n",
      " 38  tres_alloc_vmem       395914 non-null  int64  \n",
      " 39  tres_req_pages        395914 non-null  int64  \n",
      " 40  tres_alloc_pages      395914 non-null  int64  \n",
      " 41  tres_req_gpu:tesla    395914 non-null  int64  \n",
      " 42  tres_alloc_gpu:tesla  395914 non-null  int64  \n",
      " 43  tres_req_gpu:volta    395914 non-null  int64  \n",
      " 44  tres_alloc_gpu:volta  395914 non-null  int64  \n",
      " 45  model                 3430 non-null    object \n",
      "dtypes: float64(1), int64(39), object(4), uint64(2)\n",
      "memory usage: 138.9+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "id_job                       0\n",
       "id_array_job                 0\n",
       "id_array_task                0\n",
       "id_user                      0\n",
       "kill_requid                  0\n",
       "nodes_alloc                  0\n",
       "cpus_req                     0\n",
       "derived_ec                   0\n",
       "exit_code                    0\n",
       "gres_used               395914\n",
       "array_max_tasks              0\n",
       "array_task_pending           0\n",
       "constraints                  0\n",
       "flags                        0\n",
       "mem_req                      0\n",
       "partition                    0\n",
       "priority                     0\n",
       "state                        0\n",
       "timelimit                    0\n",
       "time_suspended               0\n",
       "track_steps                  0\n",
       "job_type                     0\n",
       "is_gpu                       0\n",
       "time_duration                0\n",
       "submission_delay             0\n",
       "tres_req_cpu                 0\n",
       "tres_alloc_cpu               0\n",
       "tres_req_mem                 0\n",
       "tres_alloc_mem               0\n",
       "tres_req_energy              0\n",
       "tres_alloc_energy            0\n",
       "tres_req_node                0\n",
       "tres_alloc_node              0\n",
       "tres_req_billing             0\n",
       "tres_alloc_billing           0\n",
       "tres_req_fs                  0\n",
       "tres_alloc_fs                0\n",
       "tres_req_vmem                0\n",
       "tres_alloc_vmem              0\n",
       "tres_req_pages               0\n",
       "tres_alloc_pages             0\n",
       "tres_req_gpu:tesla           0\n",
       "tres_alloc_gpu:tesla         0\n",
       "tres_req_gpu:volta           0\n",
       "tres_alloc_gpu:volta         0\n",
       "model                   392484\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.info()\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ec74e194-5cbf-4f8b-9831-9d3a71c6250f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Í≤∞Ï∏°Ïπò Ï±ÑÏö∞Í∏∞\n",
    "\n",
    "df['gres_used'] = df['gres_used'].fillna(0)\n",
    "df['model'] = df['model'].fillna('NONE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5bf09a68-d86d-4a64-a130-32364ef80d6e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "constraints ['xeon-g6' 'xeon-g6&6248' '\\\\N' 'opteron' 'xeon-e5' 'opteron&6274'\n",
      " 'xeon-p8']\n",
      "partition ['normal' 'gaia' 'xeon-p8' 'db' 'test']\n",
      "job_type ['OTHER' 'LLSUB:INTERACTIVE' 'LLSUB:BATCH' 'LLMAPREDUCE:MAP']\n",
      "model ['NONE' 'U5-64' 'U4-32' 'U4-64' 'U3-32' 'U4-128' 'U3-64' 'U5-128' 'U3-128'\n",
      " 'U5-32' 'inception3' 'resnet50' 'vgg16' 'resnet50_v1.5' 'resnet101'\n",
      " 'resnet101_v2' 'resnet152' 'resnet152_v2' 'vgg11' 'vgg19' 'inception4'\n",
      " 'schnet' 'dimenet' 'conv' 'pna' 'bert-base-uncased'\n",
      " 'distilbert-base-uncased']\n"
     ]
    }
   ],
   "source": [
    "# object ÌÉÄÏûÖÏùò Ïó¥Îßå ÏÑ†ÌÉù\n",
    "object_columns = df.select_dtypes(include=['object'])\n",
    "\n",
    "for col in object_columns.columns:\n",
    "    print(col, df[col].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c44e01d8-467a-48b6-86ac-0b667059f2e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Î≤îÏ£ºÌòï Î≥ÄÏàò Ïõê-Ìï´ Ïù∏ÏΩîÎî©\n",
    "df = pd.get_dummies(df, columns=['constraints', 'partition', 'job_type'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ad7d0c9b-bbbf-4fd1-985e-e413c82d249f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Ïª¨Îüº Ïù¥Î¶Ñ Ï†ïÏ†ú\n",
    "df.columns = df.columns.str.replace(r'[^a-zA-Z0-9_]', '_', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ee3a94ee-90d7-4ef6-9c98-edbc20c4a3a8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_job</th>\n",
       "      <th>id_array_job</th>\n",
       "      <th>id_array_task</th>\n",
       "      <th>id_user</th>\n",
       "      <th>kill_requid</th>\n",
       "      <th>nodes_alloc</th>\n",
       "      <th>cpus_req</th>\n",
       "      <th>derived_ec</th>\n",
       "      <th>exit_code</th>\n",
       "      <th>gres_used</th>\n",
       "      <th>...</th>\n",
       "      <th>constraints_xeon_p8</th>\n",
       "      <th>partition_db</th>\n",
       "      <th>partition_gaia</th>\n",
       "      <th>partition_normal</th>\n",
       "      <th>partition_test</th>\n",
       "      <th>partition_xeon_p8</th>\n",
       "      <th>job_type_LLMAPREDUCE_MAP</th>\n",
       "      <th>job_type_LLSUB_BATCH</th>\n",
       "      <th>job_type_LLSUB_INTERACTIVE</th>\n",
       "      <th>job_type_OTHER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65590191436871</td>\n",
       "      <td>14108987335445</td>\n",
       "      <td>114</td>\n",
       "      <td>87509498710061</td>\n",
       "      <td>61026541062099</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64310074400647</td>\n",
       "      <td>61177129314629</td>\n",
       "      <td>600</td>\n",
       "      <td>42770088536256</td>\n",
       "      <td>61026541062099</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34191949612627</td>\n",
       "      <td>14108987335445</td>\n",
       "      <td>115</td>\n",
       "      <td>87509498710061</td>\n",
       "      <td>61026541062099</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21630303188597</td>\n",
       "      <td>61177129314629</td>\n",
       "      <td>601</td>\n",
       "      <td>42770088536256</td>\n",
       "      <td>61026541062099</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10343100598054</td>\n",
       "      <td>61177129314629</td>\n",
       "      <td>602</td>\n",
       "      <td>42770088536256</td>\n",
       "      <td>61026541062099</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395909</th>\n",
       "      <td>75124122894379</td>\n",
       "      <td>16618712154521</td>\n",
       "      <td>4294967294</td>\n",
       "      <td>1706828023724</td>\n",
       "      <td>61026541062099</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395910</th>\n",
       "      <td>37802476679519</td>\n",
       "      <td>16618712154521</td>\n",
       "      <td>4294967294</td>\n",
       "      <td>1706828023724</td>\n",
       "      <td>61026541062099</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395911</th>\n",
       "      <td>9807128696900</td>\n",
       "      <td>38040778438207</td>\n",
       "      <td>109</td>\n",
       "      <td>48065336140816</td>\n",
       "      <td>61026541062099</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395912</th>\n",
       "      <td>42865228158509</td>\n",
       "      <td>38040778438207</td>\n",
       "      <td>110</td>\n",
       "      <td>48065336140816</td>\n",
       "      <td>61026541062099</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395913</th>\n",
       "      <td>36690157579853</td>\n",
       "      <td>38040778438207</td>\n",
       "      <td>111</td>\n",
       "      <td>48065336140816</td>\n",
       "      <td>61026541062099</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>395914 rows √ó 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                id_job    id_array_job  id_array_task         id_user  \\\n",
       "0       65590191436871  14108987335445            114  87509498710061   \n",
       "1       64310074400647  61177129314629            600  42770088536256   \n",
       "2       34191949612627  14108987335445            115  87509498710061   \n",
       "3       21630303188597  61177129314629            601  42770088536256   \n",
       "4       10343100598054  61177129314629            602  42770088536256   \n",
       "...                ...             ...            ...             ...   \n",
       "395909  75124122894379  16618712154521     4294967294   1706828023724   \n",
       "395910  37802476679519  16618712154521     4294967294   1706828023724   \n",
       "395911   9807128696900  38040778438207            109  48065336140816   \n",
       "395912  42865228158509  38040778438207            110  48065336140816   \n",
       "395913  36690157579853  38040778438207            111  48065336140816   \n",
       "\n",
       "           kill_requid  nodes_alloc  cpus_req  derived_ec  exit_code  \\\n",
       "0       61026541062099            1        20           0          0   \n",
       "1       61026541062099            1        20           0          0   \n",
       "2       61026541062099            1        20           0          0   \n",
       "3       61026541062099            1        20           0          0   \n",
       "4       61026541062099            1        20           0          0   \n",
       "...                ...          ...       ...         ...        ...   \n",
       "395909  61026541062099            1        10           0          0   \n",
       "395910  61026541062099            1        10           0          0   \n",
       "395911  61026541062099            1        20           0          0   \n",
       "395912  61026541062099            1        20           0          0   \n",
       "395913  61026541062099            1        20           0          0   \n",
       "\n",
       "        gres_used  ...  constraints_xeon_p8  partition_db  partition_gaia  \\\n",
       "0             0.0  ...                    0             0               0   \n",
       "1             0.0  ...                    0             0               0   \n",
       "2             0.0  ...                    0             0               0   \n",
       "3             0.0  ...                    0             0               0   \n",
       "4             0.0  ...                    0             0               0   \n",
       "...           ...  ...                  ...           ...             ...   \n",
       "395909        0.0  ...                    0             0               0   \n",
       "395910        0.0  ...                    0             0               0   \n",
       "395911        0.0  ...                    0             0               0   \n",
       "395912        0.0  ...                    0             0               0   \n",
       "395913        0.0  ...                    0             0               0   \n",
       "\n",
       "        partition_normal  partition_test  partition_xeon_p8  \\\n",
       "0                      1               0                  0   \n",
       "1                      1               0                  0   \n",
       "2                      1               0                  0   \n",
       "3                      1               0                  0   \n",
       "4                      1               0                  0   \n",
       "...                  ...             ...                ...   \n",
       "395909                 1               0                  0   \n",
       "395910                 1               0                  0   \n",
       "395911                 1               0                  0   \n",
       "395912                 1               0                  0   \n",
       "395913                 1               0                  0   \n",
       "\n",
       "        job_type_LLMAPREDUCE_MAP  job_type_LLSUB_BATCH  \\\n",
       "0                              0                     0   \n",
       "1                              0                     0   \n",
       "2                              0                     0   \n",
       "3                              0                     0   \n",
       "4                              0                     0   \n",
       "...                          ...                   ...   \n",
       "395909                         0                     0   \n",
       "395910                         0                     0   \n",
       "395911                         0                     0   \n",
       "395912                         0                     0   \n",
       "395913                         0                     0   \n",
       "\n",
       "        job_type_LLSUB_INTERACTIVE  job_type_OTHER  \n",
       "0                                0               1  \n",
       "1                                0               1  \n",
       "2                                0               1  \n",
       "3                                0               1  \n",
       "4                                0               1  \n",
       "...                            ...             ...  \n",
       "395909                           0               1  \n",
       "395910                           0               1  \n",
       "395911                           0               1  \n",
       "395912                           0               1  \n",
       "395913                           0               1  \n",
       "\n",
       "[395914 rows x 59 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937a3c0a-a648-40fb-92e8-345b233302e8",
   "metadata": {},
   "source": [
    "## 4. Model Training\n",
    "### 4-1. Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4f8ace26-c11c-4414-90a8-09ab2ee46da2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# 'model' Ïª¨Îüº ÎùºÎ≤® Ïù∏ÏΩîÎî©\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(df['model'])\n",
    "df = df.drop('model', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b2abdbc4-0868-44b7-ad54-db7ab17a0a72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c6cf35-ac79-4212-ac03-c86486fda624",
   "metadata": {},
   "source": [
    "### 4-2. LightGBM \n",
    "LGBM Î™®Îç∏ÏùÑ ÌïôÏäµÏãúÌÇ® ÌõÑ, log lossÎ•º Í≥ÑÏÇ∞Ìï©ÎãàÎã§."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "941b0a43-e733-4552-941c-be4c09980e23",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.051984 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2992\n",
      "[LightGBM] [Info] Number of data points in the train set: 277139, number of used features: 42\n",
      "[LightGBM] [Info] Start training from score -0.008752\n",
      "[LightGBM] [Info] Start training from score -7.787342\n",
      "[LightGBM] [Info] Start training from score -7.813776\n",
      "[LightGBM] [Info] Start training from score -7.822744\n",
      "[LightGBM] [Info] Start training from score -7.778684\n",
      "[LightGBM] [Info] Start training from score -7.744783\n",
      "[LightGBM] [Info] Start training from score -7.787342\n",
      "[LightGBM] [Info] Start training from score -7.897545\n",
      "[LightGBM] [Info] Start training from score -7.859446\n",
      "[LightGBM] [Info] Start training from score -7.850143\n",
      "[LightGBM] [Info] Start training from score -7.562461\n",
      "[LightGBM] [Info] Start training from score -9.536542\n",
      "[LightGBM] [Info] Start training from score -9.396780\n",
      "[LightGBM] [Info] Start training from score -7.787342\n",
      "[LightGBM] [Info] Start training from score -7.361790\n",
      "[LightGBM] [Info] Start training from score -7.408310\n",
      "[LightGBM] [Info] Start training from score -9.641903\n",
      "[LightGBM] [Info] Start training from score -8.620251\n",
      "[LightGBM] [Info] Start training from score -8.894688\n",
      "[LightGBM] [Info] Start training from score -8.524941\n",
      "[LightGBM] [Info] Start training from score -8.868713\n",
      "[LightGBM] [Info] Start training from score -8.201541\n",
      "[LightGBM] [Info] Start training from score -8.357887\n",
      "[LightGBM] [Info] Start training from score -9.441232\n",
      "[LightGBM] [Info] Start training from score -7.641925\n",
      "[LightGBM] [Info] Start training from score -7.688087\n",
      "[LightGBM] [Info] Start training from score -7.597801\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.0394073\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 0.0394073\n",
      "LightGBM Log Loss: 0.039559376525427056\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "# 1. LightGBM\n",
    "train_data = lgb.Dataset(X_train, label=y_train)\n",
    "valid_data = lgb.Dataset(X_valid, label=y_valid)\n",
    "\n",
    "params_lgb = {\n",
    "    'objective': 'multiclass',\n",
    "    'metric': 'multi_logloss',\n",
    "    'num_class': len(np.unique(y_train)),\n",
    "    'learning_rate': 0.01,\n",
    "    'num_leaves': 31\n",
    "}\n",
    "\n",
    "lgb_model = lgb.train(\n",
    "    params_lgb,\n",
    "    train_data,\n",
    "    valid_sets=[valid_data],\n",
    "    callbacks=[lgb.early_stopping(stopping_rounds=3), lgb.log_evaluation(period=100)]\n",
    ")\n",
    "\n",
    "# ÏòàÏ∏° Í≤∞Í≥ºÏùò ÌôïÎ•†ÏùÑ Í≥ÑÏÇ∞\n",
    "lgb_pred = lgb_model.predict(X_valid, raw_score=False)\n",
    "\n",
    "# Î™®Îç∏ Ï†ÄÏû•\n",
    "with open('model/lgb_model.pkl', 'wb') as f:\n",
    "    pickle.dump(lgb_model, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "05ef2bd6-8e8b-4c1a-942e-ba8c31e5cea1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM Log Loss: 0.039559376525427056\n"
     ]
    }
   ],
   "source": [
    "# Î™®Îç∏ Î∂àÎü¨Ïò§Í∏∞\n",
    "with open('model/lgb_model.pkl', 'rb') as f:\n",
    "    lgb_model = pickle.load(f)\n",
    "    \n",
    "# Î°úÍ∑∏ ÏÜêÏã§ Í≥ÑÏÇ∞\n",
    "lgb_log_loss = log_loss(y_valid, lgb_pred)\n",
    "print(f'LightGBM Log Loss: {lgb_log_loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d2cc08-dbdf-43c1-aa89-ebe776b98ebc",
   "metadata": {},
   "source": [
    "### 4-3. XGBoost\n",
    "XGBoost Î™®Îç∏ÏùÑ ÌïôÏäµÏãúÌÇ® ÌõÑ, log_lossÎ•º Í≥ÑÏÇ∞Ìï©ÎãàÎã§."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ac8ea33c-6fc6-4c9b-a97b-aa5fbbf18cf1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/xgboost/core.py:265: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc 2.28+) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-mlogloss:3.16233\n",
      "[1]\teval-mlogloss:3.04572\n",
      "[2]\teval-mlogloss:2.94197\n",
      "[3]\teval-mlogloss:2.84861\n",
      "[4]\teval-mlogloss:2.76359\n",
      "[5]\teval-mlogloss:2.68562\n",
      "[6]\teval-mlogloss:2.61358\n",
      "[7]\teval-mlogloss:2.54656\n",
      "[8]\teval-mlogloss:2.48399\n",
      "[9]\teval-mlogloss:2.42529\n",
      "[10]\teval-mlogloss:2.36999\n",
      "[11]\teval-mlogloss:2.31772\n",
      "[12]\teval-mlogloss:2.26817\n",
      "[13]\teval-mlogloss:2.22107\n",
      "[14]\teval-mlogloss:2.17619\n",
      "[15]\teval-mlogloss:2.13334\n",
      "[16]\teval-mlogloss:2.09234\n",
      "[17]\teval-mlogloss:2.05303\n",
      "[18]\teval-mlogloss:2.01529\n",
      "[19]\teval-mlogloss:1.97902\n",
      "[20]\teval-mlogloss:1.94408\n",
      "[21]\teval-mlogloss:1.91038\n",
      "[22]\teval-mlogloss:1.87787\n",
      "[23]\teval-mlogloss:1.84643\n",
      "[24]\teval-mlogloss:1.81601\n",
      "[25]\teval-mlogloss:1.78657\n",
      "[26]\teval-mlogloss:1.75802\n",
      "[27]\teval-mlogloss:1.73034\n",
      "[28]\teval-mlogloss:1.70345\n",
      "[29]\teval-mlogloss:1.67731\n",
      "[30]\teval-mlogloss:1.65191\n",
      "[31]\teval-mlogloss:1.62719\n",
      "[32]\teval-mlogloss:1.60314\n",
      "[33]\teval-mlogloss:1.57968\n",
      "[34]\teval-mlogloss:1.55682\n",
      "[35]\teval-mlogloss:1.53453\n",
      "[36]\teval-mlogloss:1.51278\n",
      "[37]\teval-mlogloss:1.49155\n",
      "[38]\teval-mlogloss:1.47080\n",
      "[39]\teval-mlogloss:1.45053\n",
      "[40]\teval-mlogloss:1.43072\n",
      "[41]\teval-mlogloss:1.41135\n",
      "[42]\teval-mlogloss:1.39239\n",
      "[43]\teval-mlogloss:1.37383\n",
      "[44]\teval-mlogloss:1.35567\n",
      "[45]\teval-mlogloss:1.33788\n",
      "[46]\teval-mlogloss:1.32045\n",
      "[47]\teval-mlogloss:1.30336\n",
      "[48]\teval-mlogloss:1.28661\n",
      "[49]\teval-mlogloss:1.27019\n",
      "[50]\teval-mlogloss:1.25409\n",
      "[51]\teval-mlogloss:1.23829\n",
      "[52]\teval-mlogloss:1.22278\n",
      "[53]\teval-mlogloss:1.20755\n",
      "[54]\teval-mlogloss:1.19260\n",
      "[55]\teval-mlogloss:1.17792\n",
      "[56]\teval-mlogloss:1.16350\n",
      "[57]\teval-mlogloss:1.14933\n",
      "[58]\teval-mlogloss:1.13540\n",
      "[59]\teval-mlogloss:1.12171\n",
      "[60]\teval-mlogloss:1.10826\n",
      "[61]\teval-mlogloss:1.09503\n",
      "[62]\teval-mlogloss:1.08201\n",
      "[63]\teval-mlogloss:1.06921\n",
      "[64]\teval-mlogloss:1.05662\n",
      "[65]\teval-mlogloss:1.04423\n",
      "[66]\teval-mlogloss:1.03203\n",
      "[67]\teval-mlogloss:1.02003\n",
      "[68]\teval-mlogloss:1.00821\n",
      "[69]\teval-mlogloss:0.99659\n",
      "[70]\teval-mlogloss:0.98513\n",
      "[71]\teval-mlogloss:0.97385\n",
      "[72]\teval-mlogloss:0.96274\n",
      "[73]\teval-mlogloss:0.95180\n",
      "[74]\teval-mlogloss:0.94101\n",
      "[75]\teval-mlogloss:0.93039\n",
      "[76]\teval-mlogloss:0.91992\n",
      "[77]\teval-mlogloss:0.90960\n",
      "[78]\teval-mlogloss:0.89943\n",
      "[79]\teval-mlogloss:0.88941\n",
      "[80]\teval-mlogloss:0.87952\n",
      "[81]\teval-mlogloss:0.86978\n",
      "[82]\teval-mlogloss:0.86017\n",
      "[83]\teval-mlogloss:0.85070\n",
      "[84]\teval-mlogloss:0.84135\n",
      "[85]\teval-mlogloss:0.83214\n",
      "[86]\teval-mlogloss:0.82305\n",
      "[87]\teval-mlogloss:0.81408\n",
      "[88]\teval-mlogloss:0.80523\n",
      "[89]\teval-mlogloss:0.79650\n",
      "[90]\teval-mlogloss:0.78789\n",
      "[91]\teval-mlogloss:0.77939\n",
      "[92]\teval-mlogloss:0.77100\n",
      "[93]\teval-mlogloss:0.76272\n",
      "[94]\teval-mlogloss:0.75455\n",
      "[95]\teval-mlogloss:0.74649\n",
      "[96]\teval-mlogloss:0.73853\n",
      "[97]\teval-mlogloss:0.73067\n",
      "[98]\teval-mlogloss:0.72291\n",
      "[99]\teval-mlogloss:0.71525\n",
      "[100]\teval-mlogloss:0.70769\n",
      "[101]\teval-mlogloss:0.70021\n",
      "[102]\teval-mlogloss:0.69283\n",
      "[103]\teval-mlogloss:0.68555\n",
      "[104]\teval-mlogloss:0.67835\n",
      "[105]\teval-mlogloss:0.67124\n",
      "[106]\teval-mlogloss:0.66422\n",
      "[107]\teval-mlogloss:0.65728\n",
      "[108]\teval-mlogloss:0.65043\n",
      "[109]\teval-mlogloss:0.64366\n",
      "[110]\teval-mlogloss:0.63697\n",
      "[111]\teval-mlogloss:0.63037\n",
      "[112]\teval-mlogloss:0.62384\n",
      "[113]\teval-mlogloss:0.61739\n",
      "[114]\teval-mlogloss:0.61102\n",
      "[115]\teval-mlogloss:0.60472\n",
      "[116]\teval-mlogloss:0.59850\n",
      "[117]\teval-mlogloss:0.59235\n",
      "[118]\teval-mlogloss:0.58628\n",
      "[119]\teval-mlogloss:0.58027\n",
      "[120]\teval-mlogloss:0.57433\n",
      "[121]\teval-mlogloss:0.56846\n",
      "[122]\teval-mlogloss:0.56267\n",
      "[123]\teval-mlogloss:0.55693\n",
      "[124]\teval-mlogloss:0.55127\n",
      "[125]\teval-mlogloss:0.54567\n",
      "[126]\teval-mlogloss:0.54013\n",
      "[127]\teval-mlogloss:0.53466\n",
      "[128]\teval-mlogloss:0.52925\n",
      "[129]\teval-mlogloss:0.52390\n",
      "[130]\teval-mlogloss:0.51861\n",
      "[131]\teval-mlogloss:0.51338\n",
      "[132]\teval-mlogloss:0.50821\n",
      "[133]\teval-mlogloss:0.50309\n",
      "[134]\teval-mlogloss:0.49804\n",
      "[135]\teval-mlogloss:0.49304\n",
      "[136]\teval-mlogloss:0.48810\n",
      "[137]\teval-mlogloss:0.48321\n",
      "[138]\teval-mlogloss:0.47837\n",
      "[139]\teval-mlogloss:0.47360\n",
      "[140]\teval-mlogloss:0.46887\n",
      "[141]\teval-mlogloss:0.46419\n",
      "[142]\teval-mlogloss:0.45957\n",
      "[143]\teval-mlogloss:0.45500\n",
      "[144]\teval-mlogloss:0.45048\n",
      "[145]\teval-mlogloss:0.44601\n",
      "[146]\teval-mlogloss:0.44158\n",
      "[147]\teval-mlogloss:0.43721\n",
      "[148]\teval-mlogloss:0.43288\n",
      "[149]\teval-mlogloss:0.42860\n",
      "[150]\teval-mlogloss:0.42437\n",
      "[151]\teval-mlogloss:0.42018\n",
      "[152]\teval-mlogloss:0.41604\n",
      "[153]\teval-mlogloss:0.41194\n",
      "[154]\teval-mlogloss:0.40789\n",
      "[155]\teval-mlogloss:0.40388\n",
      "[156]\teval-mlogloss:0.39991\n",
      "[157]\teval-mlogloss:0.39599\n",
      "[158]\teval-mlogloss:0.39211\n",
      "[159]\teval-mlogloss:0.38827\n",
      "[160]\teval-mlogloss:0.38447\n",
      "[161]\teval-mlogloss:0.38072\n",
      "[162]\teval-mlogloss:0.37700\n",
      "[163]\teval-mlogloss:0.37332\n",
      "[164]\teval-mlogloss:0.36968\n",
      "[165]\teval-mlogloss:0.36608\n",
      "[166]\teval-mlogloss:0.36252\n",
      "[167]\teval-mlogloss:0.35900\n",
      "[168]\teval-mlogloss:0.35551\n",
      "[169]\teval-mlogloss:0.35207\n",
      "[170]\teval-mlogloss:0.34865\n",
      "[171]\teval-mlogloss:0.34528\n",
      "[172]\teval-mlogloss:0.34194\n",
      "[173]\teval-mlogloss:0.33863\n",
      "[174]\teval-mlogloss:0.33536\n",
      "[175]\teval-mlogloss:0.33212\n",
      "[176]\teval-mlogloss:0.32892\n",
      "[177]\teval-mlogloss:0.32575\n",
      "[178]\teval-mlogloss:0.32261\n",
      "[179]\teval-mlogloss:0.31951\n",
      "[180]\teval-mlogloss:0.31644\n",
      "[181]\teval-mlogloss:0.31340\n",
      "[182]\teval-mlogloss:0.31039\n",
      "[183]\teval-mlogloss:0.30742\n",
      "[184]\teval-mlogloss:0.30448\n",
      "[185]\teval-mlogloss:0.30157\n",
      "[186]\teval-mlogloss:0.29868\n",
      "[187]\teval-mlogloss:0.29583\n",
      "[188]\teval-mlogloss:0.29301\n",
      "[189]\teval-mlogloss:0.29022\n",
      "[190]\teval-mlogloss:0.28745\n",
      "[191]\teval-mlogloss:0.28472\n",
      "[192]\teval-mlogloss:0.28201\n",
      "[193]\teval-mlogloss:0.27933\n",
      "[194]\teval-mlogloss:0.27668\n",
      "[195]\teval-mlogloss:0.27406\n",
      "[196]\teval-mlogloss:0.27146\n",
      "[197]\teval-mlogloss:0.26889\n",
      "[198]\teval-mlogloss:0.26635\n",
      "[199]\teval-mlogloss:0.26383\n",
      "[200]\teval-mlogloss:0.26134\n",
      "[201]\teval-mlogloss:0.25888\n",
      "[202]\teval-mlogloss:0.25644\n",
      "[203]\teval-mlogloss:0.25402\n",
      "[204]\teval-mlogloss:0.25163\n",
      "[205]\teval-mlogloss:0.24927\n",
      "[206]\teval-mlogloss:0.24692\n",
      "[207]\teval-mlogloss:0.24461\n",
      "[208]\teval-mlogloss:0.24231\n",
      "[209]\teval-mlogloss:0.24004\n",
      "[210]\teval-mlogloss:0.23780\n",
      "[211]\teval-mlogloss:0.23557\n",
      "[212]\teval-mlogloss:0.23337\n",
      "[213]\teval-mlogloss:0.23119\n",
      "[214]\teval-mlogloss:0.22903\n",
      "[215]\teval-mlogloss:0.22689\n",
      "[216]\teval-mlogloss:0.22478\n",
      "[217]\teval-mlogloss:0.22269\n",
      "[218]\teval-mlogloss:0.22062\n",
      "[219]\teval-mlogloss:0.21857\n",
      "[220]\teval-mlogloss:0.21654\n",
      "[221]\teval-mlogloss:0.21453\n",
      "[222]\teval-mlogloss:0.21255\n",
      "[223]\teval-mlogloss:0.21058\n",
      "[224]\teval-mlogloss:0.20863\n",
      "[225]\teval-mlogloss:0.20670\n",
      "[226]\teval-mlogloss:0.20480\n",
      "[227]\teval-mlogloss:0.20291\n",
      "[228]\teval-mlogloss:0.20104\n",
      "[229]\teval-mlogloss:0.19919\n",
      "[230]\teval-mlogloss:0.19736\n",
      "[231]\teval-mlogloss:0.19555\n",
      "[232]\teval-mlogloss:0.19375\n",
      "[233]\teval-mlogloss:0.19197\n",
      "[234]\teval-mlogloss:0.19022\n",
      "[235]\teval-mlogloss:0.18847\n",
      "[236]\teval-mlogloss:0.18675\n",
      "[237]\teval-mlogloss:0.18505\n",
      "[238]\teval-mlogloss:0.18336\n",
      "[239]\teval-mlogloss:0.18169\n",
      "[240]\teval-mlogloss:0.18003\n",
      "[241]\teval-mlogloss:0.17840\n",
      "[242]\teval-mlogloss:0.17678\n",
      "[243]\teval-mlogloss:0.17517\n",
      "[244]\teval-mlogloss:0.17358\n",
      "[245]\teval-mlogloss:0.17201\n",
      "[246]\teval-mlogloss:0.17045\n",
      "[247]\teval-mlogloss:0.16891\n",
      "[248]\teval-mlogloss:0.16739\n",
      "[249]\teval-mlogloss:0.16588\n",
      "[250]\teval-mlogloss:0.16438\n",
      "[251]\teval-mlogloss:0.16290\n",
      "[252]\teval-mlogloss:0.16144\n",
      "[253]\teval-mlogloss:0.15999\n",
      "[254]\teval-mlogloss:0.15855\n",
      "[255]\teval-mlogloss:0.15713\n",
      "[256]\teval-mlogloss:0.15572\n",
      "[257]\teval-mlogloss:0.15433\n",
      "[258]\teval-mlogloss:0.15295\n",
      "[259]\teval-mlogloss:0.15159\n",
      "[260]\teval-mlogloss:0.15023\n",
      "[261]\teval-mlogloss:0.14890\n",
      "[262]\teval-mlogloss:0.14757\n",
      "[263]\teval-mlogloss:0.14626\n",
      "[264]\teval-mlogloss:0.14496\n",
      "[265]\teval-mlogloss:0.14368\n",
      "[266]\teval-mlogloss:0.14240\n",
      "[267]\teval-mlogloss:0.14115\n",
      "[268]\teval-mlogloss:0.13990\n",
      "[269]\teval-mlogloss:0.13867\n",
      "[270]\teval-mlogloss:0.13744\n",
      "[271]\teval-mlogloss:0.13623\n",
      "[272]\teval-mlogloss:0.13503\n",
      "[273]\teval-mlogloss:0.13385\n",
      "[274]\teval-mlogloss:0.13268\n",
      "[275]\teval-mlogloss:0.13151\n",
      "[276]\teval-mlogloss:0.13036\n",
      "[277]\teval-mlogloss:0.12922\n",
      "[278]\teval-mlogloss:0.12810\n",
      "[279]\teval-mlogloss:0.12698\n",
      "[280]\teval-mlogloss:0.12587\n",
      "[281]\teval-mlogloss:0.12478\n",
      "[282]\teval-mlogloss:0.12370\n",
      "[283]\teval-mlogloss:0.12262\n",
      "[284]\teval-mlogloss:0.12156\n",
      "[285]\teval-mlogloss:0.12051\n",
      "[286]\teval-mlogloss:0.11947\n",
      "[287]\teval-mlogloss:0.11844\n",
      "[288]\teval-mlogloss:0.11742\n",
      "[289]\teval-mlogloss:0.11641\n",
      "[290]\teval-mlogloss:0.11541\n",
      "[291]\teval-mlogloss:0.11442\n",
      "[292]\teval-mlogloss:0.11344\n",
      "[293]\teval-mlogloss:0.11247\n",
      "[294]\teval-mlogloss:0.11151\n",
      "[295]\teval-mlogloss:0.11056\n",
      "[296]\teval-mlogloss:0.10962\n",
      "[297]\teval-mlogloss:0.10869\n",
      "[298]\teval-mlogloss:0.10776\n",
      "[299]\teval-mlogloss:0.10685\n",
      "[300]\teval-mlogloss:0.10595\n",
      "[301]\teval-mlogloss:0.10505\n",
      "[302]\teval-mlogloss:0.10416\n",
      "[303]\teval-mlogloss:0.10329\n",
      "[304]\teval-mlogloss:0.10242\n",
      "[305]\teval-mlogloss:0.10156\n",
      "[306]\teval-mlogloss:0.10071\n",
      "[307]\teval-mlogloss:0.09986\n",
      "[308]\teval-mlogloss:0.09903\n",
      "[309]\teval-mlogloss:0.09820\n",
      "[310]\teval-mlogloss:0.09738\n",
      "[311]\teval-mlogloss:0.09657\n",
      "[312]\teval-mlogloss:0.09577\n",
      "[313]\teval-mlogloss:0.09497\n",
      "[314]\teval-mlogloss:0.09418\n",
      "[315]\teval-mlogloss:0.09341\n",
      "[316]\teval-mlogloss:0.09263\n",
      "[317]\teval-mlogloss:0.09187\n",
      "[318]\teval-mlogloss:0.09111\n",
      "[319]\teval-mlogloss:0.09036\n",
      "[320]\teval-mlogloss:0.08962\n",
      "[321]\teval-mlogloss:0.08889\n",
      "[322]\teval-mlogloss:0.08816\n",
      "[323]\teval-mlogloss:0.08744\n",
      "[324]\teval-mlogloss:0.08673\n",
      "[325]\teval-mlogloss:0.08602\n",
      "[326]\teval-mlogloss:0.08532\n",
      "[327]\teval-mlogloss:0.08463\n",
      "[328]\teval-mlogloss:0.08395\n",
      "[329]\teval-mlogloss:0.08327\n",
      "[330]\teval-mlogloss:0.08259\n",
      "[331]\teval-mlogloss:0.08193\n",
      "[332]\teval-mlogloss:0.08127\n",
      "[333]\teval-mlogloss:0.08062\n",
      "[334]\teval-mlogloss:0.07997\n",
      "[335]\teval-mlogloss:0.07933\n",
      "[336]\teval-mlogloss:0.07870\n",
      "[337]\teval-mlogloss:0.07807\n",
      "[338]\teval-mlogloss:0.07745\n",
      "[339]\teval-mlogloss:0.07684\n",
      "[340]\teval-mlogloss:0.07623\n",
      "[341]\teval-mlogloss:0.07563\n",
      "[342]\teval-mlogloss:0.07503\n",
      "[343]\teval-mlogloss:0.07444\n",
      "[344]\teval-mlogloss:0.07385\n",
      "[345]\teval-mlogloss:0.07328\n",
      "[346]\teval-mlogloss:0.07270\n",
      "[347]\teval-mlogloss:0.07213\n",
      "[348]\teval-mlogloss:0.07157\n",
      "[349]\teval-mlogloss:0.07102\n",
      "[350]\teval-mlogloss:0.07047\n",
      "[351]\teval-mlogloss:0.06992\n",
      "[352]\teval-mlogloss:0.06938\n",
      "[353]\teval-mlogloss:0.06885\n",
      "[354]\teval-mlogloss:0.06832\n",
      "[355]\teval-mlogloss:0.06779\n",
      "[356]\teval-mlogloss:0.06728\n",
      "[357]\teval-mlogloss:0.06676\n",
      "[358]\teval-mlogloss:0.06625\n",
      "[359]\teval-mlogloss:0.06575\n",
      "[360]\teval-mlogloss:0.06525\n",
      "[361]\teval-mlogloss:0.06476\n",
      "[362]\teval-mlogloss:0.06427\n",
      "[363]\teval-mlogloss:0.06379\n",
      "[364]\teval-mlogloss:0.06331\n",
      "[365]\teval-mlogloss:0.06283\n",
      "[366]\teval-mlogloss:0.06236\n",
      "[367]\teval-mlogloss:0.06190\n",
      "[368]\teval-mlogloss:0.06144\n",
      "[369]\teval-mlogloss:0.06098\n",
      "[370]\teval-mlogloss:0.06053\n",
      "[371]\teval-mlogloss:0.06009\n",
      "[372]\teval-mlogloss:0.05964\n",
      "[373]\teval-mlogloss:0.05921\n",
      "[374]\teval-mlogloss:0.05877\n",
      "[375]\teval-mlogloss:0.05834\n",
      "[376]\teval-mlogloss:0.05792\n",
      "[377]\teval-mlogloss:0.05750\n",
      "[378]\teval-mlogloss:0.05708\n",
      "[379]\teval-mlogloss:0.05667\n",
      "[380]\teval-mlogloss:0.05626\n",
      "[381]\teval-mlogloss:0.05586\n",
      "[382]\teval-mlogloss:0.05546\n",
      "[383]\teval-mlogloss:0.05506\n",
      "[384]\teval-mlogloss:0.05467\n",
      "[385]\teval-mlogloss:0.05428\n",
      "[386]\teval-mlogloss:0.05390\n",
      "[387]\teval-mlogloss:0.05352\n",
      "[388]\teval-mlogloss:0.05314\n",
      "[389]\teval-mlogloss:0.05276\n",
      "[390]\teval-mlogloss:0.05239\n",
      "[391]\teval-mlogloss:0.05203\n",
      "[392]\teval-mlogloss:0.05166\n",
      "[393]\teval-mlogloss:0.05130\n",
      "[394]\teval-mlogloss:0.05095\n",
      "[395]\teval-mlogloss:0.05059\n",
      "[396]\teval-mlogloss:0.05025\n",
      "[397]\teval-mlogloss:0.04990\n",
      "[398]\teval-mlogloss:0.04956\n",
      "[399]\teval-mlogloss:0.04922\n",
      "[400]\teval-mlogloss:0.04888\n",
      "[401]\teval-mlogloss:0.04855\n",
      "[402]\teval-mlogloss:0.04822\n",
      "[403]\teval-mlogloss:0.04789\n",
      "[404]\teval-mlogloss:0.04757\n",
      "[405]\teval-mlogloss:0.04725\n",
      "[406]\teval-mlogloss:0.04693\n",
      "[407]\teval-mlogloss:0.04662\n",
      "[408]\teval-mlogloss:0.04631\n",
      "[409]\teval-mlogloss:0.04600\n",
      "[410]\teval-mlogloss:0.04570\n",
      "[411]\teval-mlogloss:0.04539\n",
      "[412]\teval-mlogloss:0.04510\n",
      "[413]\teval-mlogloss:0.04480\n",
      "[414]\teval-mlogloss:0.04451\n",
      "[415]\teval-mlogloss:0.04422\n",
      "[416]\teval-mlogloss:0.04393\n",
      "[417]\teval-mlogloss:0.04365\n",
      "[418]\teval-mlogloss:0.04337\n",
      "[419]\teval-mlogloss:0.04309\n",
      "[420]\teval-mlogloss:0.04282\n",
      "[421]\teval-mlogloss:0.04254\n",
      "[422]\teval-mlogloss:0.04227\n",
      "[423]\teval-mlogloss:0.04200\n",
      "[424]\teval-mlogloss:0.04174\n",
      "[425]\teval-mlogloss:0.04148\n",
      "[426]\teval-mlogloss:0.04122\n",
      "[427]\teval-mlogloss:0.04096\n",
      "[428]\teval-mlogloss:0.04071\n",
      "[429]\teval-mlogloss:0.04045\n",
      "[430]\teval-mlogloss:0.04020\n",
      "[431]\teval-mlogloss:0.03996\n",
      "[432]\teval-mlogloss:0.03971\n",
      "[433]\teval-mlogloss:0.03947\n",
      "[434]\teval-mlogloss:0.03923\n",
      "[435]\teval-mlogloss:0.03899\n",
      "[436]\teval-mlogloss:0.03875\n",
      "[437]\teval-mlogloss:0.03852\n",
      "[438]\teval-mlogloss:0.03829\n",
      "[439]\teval-mlogloss:0.03806\n",
      "[440]\teval-mlogloss:0.03783\n",
      "[441]\teval-mlogloss:0.03761\n",
      "[442]\teval-mlogloss:0.03739\n",
      "[443]\teval-mlogloss:0.03717\n",
      "[444]\teval-mlogloss:0.03695\n",
      "[445]\teval-mlogloss:0.03673\n",
      "[446]\teval-mlogloss:0.03652\n",
      "[447]\teval-mlogloss:0.03631\n",
      "[448]\teval-mlogloss:0.03610\n",
      "[449]\teval-mlogloss:0.03589\n",
      "[450]\teval-mlogloss:0.03569\n",
      "[451]\teval-mlogloss:0.03548\n",
      "[452]\teval-mlogloss:0.03528\n",
      "[453]\teval-mlogloss:0.03508\n",
      "[454]\teval-mlogloss:0.03488\n",
      "[455]\teval-mlogloss:0.03469\n",
      "[456]\teval-mlogloss:0.03449\n",
      "[457]\teval-mlogloss:0.03430\n",
      "[458]\teval-mlogloss:0.03411\n",
      "[459]\teval-mlogloss:0.03393\n",
      "[460]\teval-mlogloss:0.03374\n",
      "[461]\teval-mlogloss:0.03356\n",
      "[462]\teval-mlogloss:0.03337\n",
      "[463]\teval-mlogloss:0.03319\n",
      "[464]\teval-mlogloss:0.03301\n",
      "[465]\teval-mlogloss:0.03283\n",
      "[466]\teval-mlogloss:0.03266\n",
      "[467]\teval-mlogloss:0.03248\n",
      "[468]\teval-mlogloss:0.03231\n",
      "[469]\teval-mlogloss:0.03214\n",
      "[470]\teval-mlogloss:0.03197\n",
      "[471]\teval-mlogloss:0.03181\n",
      "[472]\teval-mlogloss:0.03164\n",
      "[473]\teval-mlogloss:0.03148\n",
      "[474]\teval-mlogloss:0.03131\n",
      "[475]\teval-mlogloss:0.03115\n",
      "[476]\teval-mlogloss:0.03099\n",
      "[477]\teval-mlogloss:0.03083\n",
      "[478]\teval-mlogloss:0.03067\n",
      "[479]\teval-mlogloss:0.03052\n",
      "[480]\teval-mlogloss:0.03037\n",
      "[481]\teval-mlogloss:0.03021\n",
      "[482]\teval-mlogloss:0.03006\n",
      "[483]\teval-mlogloss:0.02991\n",
      "[484]\teval-mlogloss:0.02977\n",
      "[485]\teval-mlogloss:0.02962\n",
      "[486]\teval-mlogloss:0.02948\n",
      "[487]\teval-mlogloss:0.02933\n",
      "[488]\teval-mlogloss:0.02919\n",
      "[489]\teval-mlogloss:0.02905\n",
      "[490]\teval-mlogloss:0.02891\n",
      "[491]\teval-mlogloss:0.02877\n",
      "[492]\teval-mlogloss:0.02864\n",
      "[493]\teval-mlogloss:0.02850\n",
      "[494]\teval-mlogloss:0.02836\n",
      "[495]\teval-mlogloss:0.02823\n",
      "[496]\teval-mlogloss:0.02810\n",
      "[497]\teval-mlogloss:0.02797\n",
      "[498]\teval-mlogloss:0.02784\n",
      "[499]\teval-mlogloss:0.02771\n",
      "[500]\teval-mlogloss:0.02758\n",
      "[501]\teval-mlogloss:0.02746\n",
      "[502]\teval-mlogloss:0.02733\n",
      "[503]\teval-mlogloss:0.02721\n",
      "[504]\teval-mlogloss:0.02709\n",
      "[505]\teval-mlogloss:0.02697\n",
      "[506]\teval-mlogloss:0.02685\n",
      "[507]\teval-mlogloss:0.02673\n",
      "[508]\teval-mlogloss:0.02661\n",
      "[509]\teval-mlogloss:0.02649\n",
      "[510]\teval-mlogloss:0.02638\n",
      "[511]\teval-mlogloss:0.02626\n",
      "[512]\teval-mlogloss:0.02615\n",
      "[513]\teval-mlogloss:0.02604\n",
      "[514]\teval-mlogloss:0.02593\n",
      "[515]\teval-mlogloss:0.02582\n",
      "[516]\teval-mlogloss:0.02571\n",
      "[517]\teval-mlogloss:0.02560\n",
      "[518]\teval-mlogloss:0.02549\n",
      "[519]\teval-mlogloss:0.02539\n",
      "[520]\teval-mlogloss:0.02528\n",
      "[521]\teval-mlogloss:0.02518\n",
      "[522]\teval-mlogloss:0.02508\n",
      "[523]\teval-mlogloss:0.02497\n",
      "[524]\teval-mlogloss:0.02487\n",
      "[525]\teval-mlogloss:0.02477\n",
      "[526]\teval-mlogloss:0.02468\n",
      "[527]\teval-mlogloss:0.02458\n",
      "[528]\teval-mlogloss:0.02448\n",
      "[529]\teval-mlogloss:0.02438\n",
      "[530]\teval-mlogloss:0.02429\n",
      "[531]\teval-mlogloss:0.02419\n",
      "[532]\teval-mlogloss:0.02410\n",
      "[533]\teval-mlogloss:0.02401\n",
      "[534]\teval-mlogloss:0.02392\n",
      "[535]\teval-mlogloss:0.02383\n",
      "[536]\teval-mlogloss:0.02374\n",
      "[537]\teval-mlogloss:0.02365\n",
      "[538]\teval-mlogloss:0.02356\n",
      "[539]\teval-mlogloss:0.02347\n",
      "[540]\teval-mlogloss:0.02338\n",
      "[541]\teval-mlogloss:0.02330\n",
      "[542]\teval-mlogloss:0.02321\n",
      "[543]\teval-mlogloss:0.02313\n",
      "[544]\teval-mlogloss:0.02304\n",
      "[545]\teval-mlogloss:0.02296\n",
      "[546]\teval-mlogloss:0.02288\n",
      "[547]\teval-mlogloss:0.02280\n",
      "[548]\teval-mlogloss:0.02272\n",
      "[549]\teval-mlogloss:0.02264\n",
      "[550]\teval-mlogloss:0.02256\n",
      "[551]\teval-mlogloss:0.02248\n",
      "[552]\teval-mlogloss:0.02240\n",
      "[553]\teval-mlogloss:0.02233\n",
      "[554]\teval-mlogloss:0.02225\n",
      "[555]\teval-mlogloss:0.02218\n",
      "[556]\teval-mlogloss:0.02210\n",
      "[557]\teval-mlogloss:0.02203\n",
      "[558]\teval-mlogloss:0.02196\n",
      "[559]\teval-mlogloss:0.02188\n",
      "[560]\teval-mlogloss:0.02181\n",
      "[561]\teval-mlogloss:0.02174\n",
      "[562]\teval-mlogloss:0.02167\n",
      "[563]\teval-mlogloss:0.02160\n",
      "[564]\teval-mlogloss:0.02153\n",
      "[565]\teval-mlogloss:0.02147\n",
      "[566]\teval-mlogloss:0.02140\n",
      "[567]\teval-mlogloss:0.02133\n",
      "[568]\teval-mlogloss:0.02127\n",
      "[569]\teval-mlogloss:0.02120\n",
      "[570]\teval-mlogloss:0.02114\n",
      "[571]\teval-mlogloss:0.02107\n",
      "[572]\teval-mlogloss:0.02101\n",
      "[573]\teval-mlogloss:0.02095\n",
      "[574]\teval-mlogloss:0.02088\n",
      "[575]\teval-mlogloss:0.02082\n",
      "[576]\teval-mlogloss:0.02076\n",
      "[577]\teval-mlogloss:0.02070\n",
      "[578]\teval-mlogloss:0.02064\n",
      "[579]\teval-mlogloss:0.02058\n",
      "[580]\teval-mlogloss:0.02052\n",
      "[581]\teval-mlogloss:0.02046\n",
      "[582]\teval-mlogloss:0.02040\n",
      "[583]\teval-mlogloss:0.02035\n",
      "[584]\teval-mlogloss:0.02029\n",
      "[585]\teval-mlogloss:0.02024\n",
      "[586]\teval-mlogloss:0.02018\n",
      "[587]\teval-mlogloss:0.02012\n",
      "[588]\teval-mlogloss:0.02007\n",
      "[589]\teval-mlogloss:0.02002\n",
      "[590]\teval-mlogloss:0.01996\n",
      "[591]\teval-mlogloss:0.01991\n",
      "[592]\teval-mlogloss:0.01986\n",
      "[593]\teval-mlogloss:0.01981\n",
      "[594]\teval-mlogloss:0.01976\n",
      "[595]\teval-mlogloss:0.01971\n",
      "[596]\teval-mlogloss:0.01966\n",
      "[597]\teval-mlogloss:0.01961\n",
      "[598]\teval-mlogloss:0.01956\n",
      "[599]\teval-mlogloss:0.01951\n",
      "[600]\teval-mlogloss:0.01946\n",
      "[601]\teval-mlogloss:0.01941\n",
      "[602]\teval-mlogloss:0.01936\n",
      "[603]\teval-mlogloss:0.01931\n",
      "[604]\teval-mlogloss:0.01927\n",
      "[605]\teval-mlogloss:0.01922\n",
      "[606]\teval-mlogloss:0.01917\n",
      "[607]\teval-mlogloss:0.01912\n",
      "[608]\teval-mlogloss:0.01908\n",
      "[609]\teval-mlogloss:0.01903\n",
      "[610]\teval-mlogloss:0.01899\n",
      "[611]\teval-mlogloss:0.01894\n",
      "[612]\teval-mlogloss:0.01890\n",
      "[613]\teval-mlogloss:0.01885\n",
      "[614]\teval-mlogloss:0.01881\n",
      "[615]\teval-mlogloss:0.01877\n",
      "[616]\teval-mlogloss:0.01872\n",
      "[617]\teval-mlogloss:0.01868\n",
      "[618]\teval-mlogloss:0.01864\n",
      "[619]\teval-mlogloss:0.01860\n",
      "[620]\teval-mlogloss:0.01856\n",
      "[621]\teval-mlogloss:0.01852\n",
      "[622]\teval-mlogloss:0.01848\n",
      "[623]\teval-mlogloss:0.01844\n",
      "[624]\teval-mlogloss:0.01840\n",
      "[625]\teval-mlogloss:0.01836\n",
      "[626]\teval-mlogloss:0.01832\n",
      "[627]\teval-mlogloss:0.01828\n",
      "[628]\teval-mlogloss:0.01824\n",
      "[629]\teval-mlogloss:0.01820\n",
      "[630]\teval-mlogloss:0.01817\n",
      "[631]\teval-mlogloss:0.01813\n",
      "[632]\teval-mlogloss:0.01809\n",
      "[633]\teval-mlogloss:0.01805\n",
      "[634]\teval-mlogloss:0.01802\n",
      "[635]\teval-mlogloss:0.01798\n",
      "[636]\teval-mlogloss:0.01795\n",
      "[637]\teval-mlogloss:0.01791\n",
      "[638]\teval-mlogloss:0.01788\n",
      "[639]\teval-mlogloss:0.01784\n",
      "[640]\teval-mlogloss:0.01781\n",
      "[641]\teval-mlogloss:0.01777\n",
      "[642]\teval-mlogloss:0.01774\n",
      "[643]\teval-mlogloss:0.01771\n",
      "[644]\teval-mlogloss:0.01767\n",
      "[645]\teval-mlogloss:0.01764\n",
      "[646]\teval-mlogloss:0.01761\n",
      "[647]\teval-mlogloss:0.01758\n",
      "[648]\teval-mlogloss:0.01755\n",
      "[649]\teval-mlogloss:0.01752\n",
      "[650]\teval-mlogloss:0.01749\n",
      "[651]\teval-mlogloss:0.01745\n",
      "[652]\teval-mlogloss:0.01742\n",
      "[653]\teval-mlogloss:0.01739\n",
      "[654]\teval-mlogloss:0.01736\n",
      "[655]\teval-mlogloss:0.01733\n",
      "[656]\teval-mlogloss:0.01730\n",
      "[657]\teval-mlogloss:0.01727\n",
      "[658]\teval-mlogloss:0.01725\n",
      "[659]\teval-mlogloss:0.01721\n",
      "[660]\teval-mlogloss:0.01719\n",
      "[661]\teval-mlogloss:0.01716\n",
      "[662]\teval-mlogloss:0.01713\n",
      "[663]\teval-mlogloss:0.01710\n",
      "[664]\teval-mlogloss:0.01708\n",
      "[665]\teval-mlogloss:0.01705\n",
      "[666]\teval-mlogloss:0.01702\n",
      "[667]\teval-mlogloss:0.01699\n",
      "[668]\teval-mlogloss:0.01697\n",
      "[669]\teval-mlogloss:0.01694\n",
      "[670]\teval-mlogloss:0.01691\n",
      "[671]\teval-mlogloss:0.01689\n",
      "[672]\teval-mlogloss:0.01686\n",
      "[673]\teval-mlogloss:0.01684\n",
      "[674]\teval-mlogloss:0.01681\n",
      "[675]\teval-mlogloss:0.01679\n",
      "[676]\teval-mlogloss:0.01676\n",
      "[677]\teval-mlogloss:0.01674\n",
      "[678]\teval-mlogloss:0.01672\n",
      "[679]\teval-mlogloss:0.01669\n",
      "[680]\teval-mlogloss:0.01667\n",
      "[681]\teval-mlogloss:0.01664\n",
      "[682]\teval-mlogloss:0.01662\n",
      "[683]\teval-mlogloss:0.01660\n",
      "[684]\teval-mlogloss:0.01658\n",
      "[685]\teval-mlogloss:0.01655\n",
      "[686]\teval-mlogloss:0.01653\n",
      "[687]\teval-mlogloss:0.01651\n",
      "[688]\teval-mlogloss:0.01649\n",
      "[689]\teval-mlogloss:0.01647\n",
      "[690]\teval-mlogloss:0.01644\n",
      "[691]\teval-mlogloss:0.01642\n",
      "[692]\teval-mlogloss:0.01640\n",
      "[693]\teval-mlogloss:0.01638\n",
      "[694]\teval-mlogloss:0.01636\n",
      "[695]\teval-mlogloss:0.01634\n",
      "[696]\teval-mlogloss:0.01632\n",
      "[697]\teval-mlogloss:0.01630\n",
      "[698]\teval-mlogloss:0.01628\n",
      "[699]\teval-mlogloss:0.01626\n",
      "[700]\teval-mlogloss:0.01624\n",
      "[701]\teval-mlogloss:0.01622\n",
      "[702]\teval-mlogloss:0.01620\n",
      "[703]\teval-mlogloss:0.01618\n",
      "[704]\teval-mlogloss:0.01616\n",
      "[705]\teval-mlogloss:0.01615\n",
      "[706]\teval-mlogloss:0.01613\n",
      "[707]\teval-mlogloss:0.01611\n",
      "[708]\teval-mlogloss:0.01609\n",
      "[709]\teval-mlogloss:0.01607\n",
      "[710]\teval-mlogloss:0.01606\n",
      "[711]\teval-mlogloss:0.01604\n",
      "[712]\teval-mlogloss:0.01602\n",
      "[713]\teval-mlogloss:0.01601\n",
      "[714]\teval-mlogloss:0.01599\n",
      "[715]\teval-mlogloss:0.01597\n",
      "[716]\teval-mlogloss:0.01595\n",
      "[717]\teval-mlogloss:0.01594\n",
      "[718]\teval-mlogloss:0.01592\n",
      "[719]\teval-mlogloss:0.01591\n",
      "[720]\teval-mlogloss:0.01589\n",
      "[721]\teval-mlogloss:0.01587\n",
      "[722]\teval-mlogloss:0.01586\n",
      "[723]\teval-mlogloss:0.01584\n",
      "[724]\teval-mlogloss:0.01583\n",
      "[725]\teval-mlogloss:0.01581\n",
      "[726]\teval-mlogloss:0.01580\n",
      "[727]\teval-mlogloss:0.01578\n",
      "[728]\teval-mlogloss:0.01577\n",
      "[729]\teval-mlogloss:0.01575\n",
      "[730]\teval-mlogloss:0.01574\n",
      "[731]\teval-mlogloss:0.01572\n",
      "[732]\teval-mlogloss:0.01571\n",
      "[733]\teval-mlogloss:0.01569\n",
      "[734]\teval-mlogloss:0.01568\n",
      "[735]\teval-mlogloss:0.01566\n",
      "[736]\teval-mlogloss:0.01565\n",
      "[737]\teval-mlogloss:0.01563\n",
      "[738]\teval-mlogloss:0.01562\n",
      "[739]\teval-mlogloss:0.01561\n",
      "[740]\teval-mlogloss:0.01559\n",
      "[741]\teval-mlogloss:0.01558\n",
      "[742]\teval-mlogloss:0.01557\n",
      "[743]\teval-mlogloss:0.01555\n",
      "[744]\teval-mlogloss:0.01554\n",
      "[745]\teval-mlogloss:0.01552\n",
      "[746]\teval-mlogloss:0.01551\n",
      "[747]\teval-mlogloss:0.01550\n",
      "[748]\teval-mlogloss:0.01548\n",
      "[749]\teval-mlogloss:0.01547\n",
      "[750]\teval-mlogloss:0.01546\n",
      "[751]\teval-mlogloss:0.01545\n",
      "[752]\teval-mlogloss:0.01543\n",
      "[753]\teval-mlogloss:0.01542\n",
      "[754]\teval-mlogloss:0.01541\n",
      "[755]\teval-mlogloss:0.01540\n",
      "[756]\teval-mlogloss:0.01538\n",
      "[757]\teval-mlogloss:0.01537\n",
      "[758]\teval-mlogloss:0.01536\n",
      "[759]\teval-mlogloss:0.01535\n",
      "[760]\teval-mlogloss:0.01533\n",
      "[761]\teval-mlogloss:0.01532\n",
      "[762]\teval-mlogloss:0.01531\n",
      "[763]\teval-mlogloss:0.01530\n",
      "[764]\teval-mlogloss:0.01529\n",
      "[765]\teval-mlogloss:0.01528\n",
      "[766]\teval-mlogloss:0.01527\n",
      "[767]\teval-mlogloss:0.01526\n",
      "[768]\teval-mlogloss:0.01525\n",
      "[769]\teval-mlogloss:0.01524\n",
      "[770]\teval-mlogloss:0.01522\n",
      "[771]\teval-mlogloss:0.01521\n",
      "[772]\teval-mlogloss:0.01520\n",
      "[773]\teval-mlogloss:0.01519\n",
      "[774]\teval-mlogloss:0.01519\n",
      "[775]\teval-mlogloss:0.01518\n",
      "[776]\teval-mlogloss:0.01517\n",
      "[777]\teval-mlogloss:0.01516\n",
      "[778]\teval-mlogloss:0.01515\n",
      "[779]\teval-mlogloss:0.01514\n",
      "[780]\teval-mlogloss:0.01513\n",
      "[781]\teval-mlogloss:0.01512\n",
      "[782]\teval-mlogloss:0.01511\n",
      "[783]\teval-mlogloss:0.01510\n",
      "[784]\teval-mlogloss:0.01509\n",
      "[785]\teval-mlogloss:0.01508\n",
      "[786]\teval-mlogloss:0.01508\n",
      "[787]\teval-mlogloss:0.01507\n",
      "[788]\teval-mlogloss:0.01506\n",
      "[789]\teval-mlogloss:0.01505\n",
      "[790]\teval-mlogloss:0.01504\n",
      "[791]\teval-mlogloss:0.01503\n",
      "[792]\teval-mlogloss:0.01502\n",
      "[793]\teval-mlogloss:0.01502\n",
      "[794]\teval-mlogloss:0.01501\n",
      "[795]\teval-mlogloss:0.01500\n",
      "[796]\teval-mlogloss:0.01499\n",
      "[797]\teval-mlogloss:0.01499\n",
      "[798]\teval-mlogloss:0.01498\n",
      "[799]\teval-mlogloss:0.01497\n",
      "XGBoost Log Loss: 0.014970162926073114\n"
     ]
    }
   ],
   "source": [
    "# 2. XGBoost\n",
    "import xgboost as xgb\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dvalid = xgb.DMatrix(X_valid, label=y_valid)\n",
    "\n",
    "params_xgb = {\n",
    "    'objective': 'multi:softprob',\n",
    "    'num_class': len(np.unique(y_train)),\n",
    "    'eval_metric': 'mlogloss',\n",
    "    'max_depth': 6,\n",
    "    'learning_rate': 0.01\n",
    "}\n",
    "\n",
    "xgb_model = xgb.train(params_xgb, dtrain, num_boost_round=800, \n",
    "                       evals=[(dvalid, 'eval')],\n",
    "                       early_stopping_rounds=3, \n",
    "                       verbose_eval=True)\n",
    "\n",
    "\n",
    "# Î™®Îç∏ Ï†ÄÏû•\n",
    "with open('model/xgb_model.pkl', 'wb') as f:\n",
    "    pickle.dump(xgb_model, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2df69ff7-5c1f-4e01-a519-f332194df1cb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Log Loss: 0.014970162926073114\n"
     ]
    }
   ],
   "source": [
    "# Î™®Îç∏ Î∂àÎü¨Ïò§Í∏∞\n",
    "with open('model/xgb_model.pkl', 'rb') as f:\n",
    "    xgb_model = pickle.load(f)\n",
    "\n",
    "\n",
    "xgb_pred = xgb_model.predict(dvalid)\n",
    "xgb_log_loss = log_loss(y_valid, xgb_pred)\n",
    "print(f'XGBoost Log Loss: {xgb_log_loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a34649-399a-4626-bf93-1214de6ad8f9",
   "metadata": {},
   "source": [
    "### 4-4. CatBoost\n",
    "CatBoost Î™®Îç∏ÏùÑ ÌïôÏäµÌïòÍ≥† Log lossÎ•º Í≥ÑÏÇ∞Ìï©ÎãàÎã§."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b115ccbe-42d3-414b-88fe-67c6d345abe8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 3.0421453\ttest: 3.0421260\tbest: 3.0421260 (0)\ttotal: 3.1s\tremaining: 41m 16s\n",
      "100:\tlearn: 0.4585894\ttest: 0.4587148\tbest: 0.4587148 (100)\ttotal: 4m 49s\tremaining: 33m 23s\n",
      "200:\tlearn: 0.1676410\ttest: 0.1680166\tbest: 0.1680166 (200)\ttotal: 9m 39s\tremaining: 28m 45s\n",
      "300:\tlearn: 0.0753511\ttest: 0.0759504\tbest: 0.0759504 (300)\ttotal: 14m 27s\tremaining: 23m 58s\n",
      "400:\tlearn: 0.0417516\ttest: 0.0424589\tbest: 0.0424589 (400)\ttotal: 19m 17s\tremaining: 19m 11s\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier, Pool\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "# Pool Í∞ùÏ≤¥ ÏÉùÏÑ±\n",
    "train_pool = Pool(X_train, y_train)\n",
    "valid_pool = Pool(X_valid, y_valid)\n",
    "\n",
    "# CatBoost Î™®Îç∏ ÏÑ§Ï†ï\n",
    "cat_model = CatBoostClassifier(\n",
    "    iterations=800,\n",
    "    learning_rate=0.01,\n",
    "    depth=6,\n",
    "    eval_metric='MultiClass',\n",
    "    early_stopping_rounds=3,\n",
    "    verbose=100\n",
    ")\n",
    "\n",
    "# Î™®Îç∏ ÌõàÎ†®\n",
    "cat_model.fit(train_pool, eval_set=valid_pool)\n",
    "\n",
    "# Ïú†Ìö®ÏÑ± Í≤ÄÏ¶ù Îç∞Ïù¥ÌÑ∞Ïóê ÎåÄÌïú ÏòàÏ∏° ÌôïÎ•† Í≥ÑÏÇ∞\n",
    "cat_proba = cat_model.predict_proba(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f039315-1838-4437-b5c3-6b36e8c13cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, ConfusionMatrixDisplay, log_loss\n",
    "import numpy as np\n",
    "\n",
    "# ÏòàÏ∏°Í∞íÏùÑ ÌÅ¥ÎûòÏä§ Î†àÏù¥Î∏îÎ°ú Î≥ÄÌôò\n",
    "lgb_pred_probs = lgb_model.predict(X_test)  # LightGBM\n",
    "lgb_pred_classes = np.argmax(lgb_pred_probs, axis=1)\n",
    "\n",
    "cat_pred_probs = cat_model.predict_proba(X_test)  # CatBoost\n",
    "cat_pred_classes = np.argmax(cat_pred_probs, axis=1)\n",
    "\n",
    "xgb_pred_probs = xgb_model.predict(xgb.DMatrix(X_test))  # XGBoost\n",
    "xgb_pred_classes = np.argmax(xgb_pred_probs, axis=1)\n",
    "\n",
    "# ÌèâÍ∞Ä ÏßÄÌëú Í≥ÑÏÇ∞\n",
    "lgb_accuracy = accuracy_score(y_test, lgb_pred_classes)\n",
    "cat_accuracy = accuracy_score(y_test, cat_pred_classes)\n",
    "xgb_accuracy = accuracy_score(y_test, xgb_pred_classes)\n",
    "\n",
    "lgb_f1 = f1_score(y_test, lgb_pred_classes, average='macro')\n",
    "cat_f1 = f1_score(y_test, cat_pred_classes, average='macro')\n",
    "xgb_f1 = f1_score(y_test, xgb_pred_classes, average='macro')\n",
    "\n",
    "lgb_log_loss = log_loss(y_test, lgb_pred_probs)\n",
    "cat_log_loss = log_loss(y_test, cat_pred_probs)\n",
    "xgb_log_loss = log_loss(y_test, xgb_pred_probs)\n",
    "\n",
    "\n",
    "# Í≤∞Í≥º Ï∂úÎ†•\n",
    "print(f\"LightGBM Accuracy: {lgb_accuracy}\")\n",
    "print(f\"CatBoost Accuracy: {cat_accuracy}\")\n",
    "print(f\"XGBoost Accuracy: {xgb_accuracy}\")\n",
    "\n",
    "print(f\"LightGBM F1 Score: {lgb_f1}\")\n",
    "print(f\"CatBoost F1 Score: {cat_f1}\")\n",
    "print(f\"XGBoost F1 Score: {xgb_f1}\")\n",
    "\n",
    "print(f\"LightGBM Log Loss: {lgb_log_loss}\")\n",
    "print(f\"CatBoost Log Loss: {cat_log_loss}\")\n",
    "print(f\"XGBoost Log Loss: {xgb_log_loss}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154aed54-d283-440d-afd6-257179cfee75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Confusion Matrix\n",
    "lgb_cm = confusion_matrix(y_test, lgb_pred_classes)\n",
    "cat_cm = confusion_matrix(y_test, cat_pred_classes)\n",
    "xgb_cm = confusion_matrix(y_test, xgb_pred_classes)\n",
    "\n",
    "# Visualize Confusion Matrix\n",
    "fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "ConfusionMatrixDisplay(confusion_matrix=lgb_cm).plot(ax=ax[0])\n",
    "ax[0].set_title('LightGBM Confusion Matrix')\n",
    "\n",
    "ConfusionMatrixDisplay(confusion_matrix=cat_cm).plot(ax=ax[1])\n",
    "ax[1].set_title('CatBoost Confusion Matrix')\n",
    "\n",
    "ConfusionMatrixDisplay(confusion_matrix=xgb_cm).plot(ax=ax[2])\n",
    "ax[2].set_title('XGBoost Confusion Matrix')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
